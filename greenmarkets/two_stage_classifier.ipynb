{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-68-87332.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-71-87778.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-55-19-156227.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-127-74-2431270.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-112-159-862538.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-55-62-166860.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-35-191-157959.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-76-83346.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-74-82-565669.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-51-46-372714.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-108-181-2437430.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-13-123-101172.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-93-94-1189449.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-89-172-1157050.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-74-94994.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-35-188-169625.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-78-21-723182.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-97-51-2267070.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-120-7-175607.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-24-142-173069.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-81-243-208379.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-67-101539.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-43-73-732187.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-31-245-171873.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-58-230-159896.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-85-210-1153699.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-17-55-170863.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-131-78-84348.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-123-131-168303.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-104-213-32289.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-62-217-387956.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-116-87-173133.json\n"
     ]
    }
   ],
   "source": [
    "#first load all recipe data\n",
    "BOrecipes = []\n",
    "BOingredients = []\n",
    "BOids = []\n",
    "BOpath = Path('~/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/')\n",
    "for i, po in enumerate(BOpath.expanduser().glob('*.json')):\n",
    "    with po.open() as fh:\n",
    "        try:\n",
    "            r = json.load(fh)\n",
    "        except Exception:\n",
    "            print(str(po))\n",
    "            continue\n",
    "        BOrecipes.append(r)\n",
    "        BOing = r.get('Ingredients')\n",
    "        BOid = r.get('RecipeID')\n",
    "        BOids.append(id)\n",
    "        if BOing is not None:\n",
    "            #BOingredients.append([i['Name'].strip(string.punctuation).lower().strip(string.digits).strip() for i in BOing if i is not None and i['Name'] is not None])\n",
    "            BOingredients.append([re.sub(r'[^a-z ]', '', i['Name'].lower().strip()) for i in BOing if i is not None and i['Name'] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want to load spoonacular data and create a dataframe that has ingredients and their aisle \n",
    "# this will be our classification data\n",
    "\n",
    "SArecipes = []\n",
    "SAingredients = []\n",
    "SAingclass = []\n",
    "SAnoise = []\n",
    "SAingID = []\n",
    "SAmeta = []\n",
    "SAmeasure = []\n",
    "\n",
    "seenID = set()\n",
    "SApath = Path('~/Dropbox/Not_work/insight/greenmarkets/spoonac/data/')\n",
    "for i, po in enumerate(SApath.expanduser().glob('*/*.json')):\n",
    "    with po.open() as fh:\n",
    "        try:\n",
    "            r = json.load(fh)\n",
    "        except Exception:\n",
    "            print(str(po))\n",
    "            continue\n",
    "        for rec in r:\n",
    "            currenting = rec['extendedIngredients']\n",
    "            for ing in currenting:\n",
    "                SAnoise.extend(i.strip() for i in ing['metaInformation'])\n",
    "                if ing['id'] in seenID:\n",
    "                    continue\n",
    "                seenID.add(ing['id']) \n",
    "                SAingredients.append(ing['name'])\n",
    "                SAingclass.append(ing['aisle'])  \n",
    "                SAingID.append(ing['id'])\n",
    "                SAmeasure.append(ing['measures']['us']['unitLong'])\n",
    "                SAmeta.extend([ing['meta']])\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient</th>\n",
       "      <th>aisle</th>\n",
       "      <th>meta</th>\n",
       "      <th>measure</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bell pepper</td>\n",
       "      <td>Produce</td>\n",
       "      <td>[seeded, chopped]</td>\n",
       "      <td>large</td>\n",
       "      <td>10211821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canned coconut milk</td>\n",
       "      <td>Canned and Jarred</td>\n",
       "      <td>[canned]</td>\n",
       "      <td>ounces</td>\n",
       "      <td>12117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carrots</td>\n",
       "      <td>Produce</td>\n",
       "      <td>[peeled, chopped]</td>\n",
       "      <td>larges</td>\n",
       "      <td>11124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cornstarch</td>\n",
       "      <td>Baking</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tbsps</td>\n",
       "      <td>20027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curry powder</td>\n",
       "      <td>Spices and Seasonings</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tbsp</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>aji amarillo</td>\n",
       "      <td>Produce;Ethnic Foods</td>\n",
       "      <td>[cut into 1/4-inch dice*]</td>\n",
       "      <td>Tbsps</td>\n",
       "      <td>10311819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>aji amarillo paste</td>\n",
       "      <td>Ethnic Foods</td>\n",
       "      <td>[]</td>\n",
       "      <td>teaspoon</td>\n",
       "      <td>1006973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>yuca</td>\n",
       "      <td>Produce</td>\n",
       "      <td>[fresh, cut into big pieces]</td>\n",
       "      <td>pound</td>\n",
       "      <td>11134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>cedar plank</td>\n",
       "      <td>Grilling Supplies;Gourmet</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>11911111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>lychee</td>\n",
       "      <td>Produce</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tbsp</td>\n",
       "      <td>9164.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1954 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ingredient                      aisle  \\\n",
       "0             bell pepper                    Produce   \n",
       "1     canned coconut milk          Canned and Jarred   \n",
       "2                 carrots                    Produce   \n",
       "3              cornstarch                     Baking   \n",
       "4            curry powder      Spices and Seasonings   \n",
       "...                   ...                        ...   \n",
       "1949         aji amarillo       Produce;Ethnic Foods   \n",
       "1950   aji amarillo paste               Ethnic Foods   \n",
       "1951                 yuca                    Produce   \n",
       "1952          cedar plank  Grilling Supplies;Gourmet   \n",
       "1953               lychee                    Produce   \n",
       "\n",
       "                              meta   measure          id  \n",
       "0                [seeded, chopped]     large  10211821.0  \n",
       "1                         [canned]    ounces     12117.0  \n",
       "2                [peeled, chopped]    larges     11124.0  \n",
       "3                               []     Tbsps     20027.0  \n",
       "4                               []      Tbsp      2015.0  \n",
       "...                            ...       ...         ...  \n",
       "1949     [cut into 1/4-inch dice*]     Tbsps  10311819.0  \n",
       "1950                            []  teaspoon   1006973.0  \n",
       "1951  [fresh, cut into big pieces]     pound     11134.0  \n",
       "1952                            []            11911111.0  \n",
       "1953                            []      Tbsp      9164.0  \n",
       "\n",
       "[1954 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab all the ingrdients from spoonacular and put in dataframe\n",
    "classifying = pd.DataFrame({'ingredient': SAingredients, 'aisle': SAingclass, 'meta': SAmeta, 'measure': SAmeasure,  'id': SAingID})\n",
    "classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some words you noticed should get added to SAnoise\n",
    "wta = ['ground', 'taste', 'ounce']\n",
    "SAnoise.extend(wta)\n",
    "SAnoise = set(SAnoise)\n",
    "#remember you can check if it is in there with: 'fresh' in SAnoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite of deduping functions\n",
    "\n",
    "#on loading we tokenize, strip punctuation&digits&spaces and make lowercase \n",
    "\n",
    "def removenoise(input_ing):\n",
    "    noise_free_ing = []\n",
    "    for word in input_ing:\n",
    "        checked = []\n",
    "        splitit = word.split()\n",
    "        checked.extend(i for i in splitit if i not in SAnoise)\n",
    "        noise_free_ing.append(' '.join(checked))\n",
    "    return noise_free_ing\n",
    "        \n",
    "#stem? lemmatize? part of speech tagging? stop words\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the dedupe functions\n",
    "nning = []\n",
    "for i in BOingredients:\n",
    "    nning.append(removenoise(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classify ingredients into aisles\n",
    "whichaisle = {}\n",
    "seen = set()\n",
    "notin = []\n",
    "for i in nning:\n",
    "    for j in i:\n",
    "        if j in seen:\n",
    "            continue\n",
    "        seen.add(j) \n",
    "        a = classifying.index[classifying['ingredient'] == j].tolist()        \n",
    "        if len(a) >= 1:\n",
    "            whichaisle[j] = classifying['aisle'][a].tolist()\n",
    "        if len(a) == 0:\n",
    "            whichaisle[j] = None\n",
    "            notin.append(j)\n",
    "\n",
    "            # okay so instead of exact matching maybe fuzzy wuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37098"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(whichaisle))\n",
    "#whichaisle\n",
    "len(notin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual W2V modeling\n",
    "# Set values for NN parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 3    # 50% of the corpus                    \n",
    "num_workers = 4       # Number of CPUs\n",
    "context = 10          # Context window size; \n",
    "downsampling = 1e-3   # threshold for configuring which \n",
    "                    # higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model = word2vec.Word2Vec(nning, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output both the w2v model and the aisle classification dict\n",
    "pickle.dump(model,open(\"bigoven/w2vmodel.pkl\",\"wb\"))\n",
    "pickle.dump(whichaisle,open(\"bigoven/aisleclassification.pkl\",\"wb\"))\n",
    "pickle.dump(SAnoise, open('bigoven/noiselist.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kalamata olives', 0.9773502349853516), ('baby spinach', 0.9714789986610413), ('plum tomatoes', 0.9671364426612854), ('pine nuts', 0.9558079838752747), ('sundried tomatoes', 0.952326774597168), ('grape tomatoes', 0.9518359899520874), ('basil leaves', 0.9489792585372925), ('cherry tomatoes', 0.9453437924385071), ('san marzano tomatoes', 0.9453309774398804), ('goat cheese', 0.9413638114929199)]\n",
      "=============\n",
      "[('sundried tomatoes', 0.9894789457321167), ('goat cheese', 0.9803232550621033), ('grape tomatoes', 0.9769477844238281), ('kalamata olives', 0.9761931300163269), ('feta cheese', 0.9714789986610413), ('artichoke hearts', 0.9684235453605652), ('pine nuts', 0.9621485471725464), ('orzo pasta', 0.9534425735473633), ('grilled chicken breasts', 0.9517673850059509), ('oil cured olives', 0.9511600732803345)]\n"
     ]
    }
   ],
   "source": [
    "#proof of concept, also not a production cell\n",
    "print(model.wv.most_similar('feta cheese'))\n",
    "print('=============')\n",
    "print(model.wv.most_similar('baby spinach'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('chicken', 'olive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
