{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use also tensor flow, there are multiple implementations of word2vec\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to vec exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-55-19-156227.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-127-74-2431270.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-112-159-862538.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-55-62-166860.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-35-191-157959.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-74-82-565669.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-51-46-372714.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-108-181-2437430.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-13-123-101172.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-93-94-1189449.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-89-172-1157050.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-35-188-169625.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-78-21-723182.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-97-51-2267070.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-120-7-175607.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-24-142-173069.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-81-243-208379.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-43-73-732187.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-31-245-171873.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-58-230-159896.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-85-210-1153699.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-17-55-170863.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-123-131-168303.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-104-213-32289.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-62-217-387956.json\n",
      "/Users/bridgitboulahanis/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/maindish-116-87-173133.json\n"
     ]
    }
   ],
   "source": [
    "#first load all recipe data\n",
    "recipes = []\n",
    "ingredients = []\n",
    "ids = []\n",
    "path = Path('~/Dropbox/Not_work/insight/greenmarkets/bigoven/maindish/')\n",
    "for i, po in enumerate(path.expanduser().glob('*.json')):\n",
    "    with po.open() as fh:\n",
    "        try:\n",
    "            r = json.load(fh)\n",
    "        except Exception:\n",
    "            print(str(po))\n",
    "            continue\n",
    "        recipes.append(r)\n",
    "        ing = r.get('Ingredients')\n",
    "        id = r.get('RecipeID')\n",
    "        ids.append(id)\n",
    "        if ing is not None:\n",
    "            ingredients.append([i['Name'] for i in ing if i is not None and i['Name'] is not None])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for NN parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 3    # 50% of the corpus                    \n",
    "num_workers = 4       # Number of CPUs\n",
    "context = 10          # Context window size; \n",
    "downsampling = 1e-3   # threshold for configuring which \n",
    "                    # higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model = word2vec.Word2Vec(ingredients, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing feta\n",
      "\n",
      "inverse [' ', ' Freshly ground black pepper  ', ' Kosher salt  ', ' olive oil', ' �1', ' �2', 'Aluminum foil', 'Coarse salt and freshly ground pepper', 'Filling: ', 'Granny Smith apple', 'Kosher salt ', 'Sauce: ', 'Stock, Chicken', 'White Wine ', 'Worcestershire ', 'all-purpose flour  ', 'anchovies', 'basil  ', 'bay', 'beef stock ', 'brie cheese', 'butter  ', 'celery stick', 'cherry or grape tomatoes', 'chicken breasts ', 'chorizo sausage', 'courgettes', 'dry white wine ', 'each)', 'egg yolks ', 'feta', 'fresh garlic ', 'fresh lemon', 'garlic   ', 'grated parmesan cheese ', 'green peas', 'ground nutmeg ', 'ground pepper ', 'honey  ', 'low-fat cottage cheese', 'pasta ', 'plum tomatoes ', 'pork chops ', 'red peppers', 'reduced-fat', 'sea salt to taste', 'shallots ', 'shredded mozzarella cheese ', 'single cream', 'soy sauce  ', 'sugar  ', 'sundried tomatoes', 'tin chopped tomatoes', 'tofu ', 'turkey stock', 'vegetable bouillon', 'white wine  ', 'whole turkey', '�1']\n",
      "counts\n",
      "('low-fat cottage cheese', 2)\n",
      "('Coarse salt and freshly ground pepper', 3)\n",
      "('Aluminum foil', 3)\n",
      "('fresh lemon', 3)\n",
      "('ground nutmeg ', 3)\n",
      "('Worcestershire ', 3)\n",
      "('butter  ', 4)\n",
      "('�1', 4)\n",
      "('feta', 5)\n",
      "('egg yolks ', 7)\n",
      "\n",
      "most similar [(' Salt; to taste ', 0.9992021322250366), ('fat free sour cream ', 0.9991497993469238), ('salsa ', 0.9989970922470093), ('red wine  ', 0.9988958239555359), ('fresh Italian parsley ', 0.9988905191421509), ('cooked long grain rice', 0.9988788366317749), ('black peppercorn', 0.998862624168396), ('chives ', 0.9987742900848389), ('sweet paprika ', 0.9987615346908569), (' Grated', 0.9987173676490784)]\n",
      "negative\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'f' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ffa5fa2897e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_ingredient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'f' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "ingredient = 'feta cheese'\n",
    "df = pd.DataFrame([i for i in ingredients if ingredient in i])\n",
    "w2v_ingredient = ingredients[1]\n",
    "w2v_ingredient = 'feta'\n",
    "print(\"testing\", w2v_ingredient)\n",
    "similar_ings = [similar_ing for similar_ing, _ in model.wv.most_similar(w2v_ingredient)]\n",
    "\n",
    "invers_similar_ings = {}\n",
    "for si in similar_ings:\n",
    "    for isi, _ in model.wv.most_similar(si):\n",
    "        invers_similar_ings.setdefault(isi, 0)\n",
    "        invers_similar_ings[isi] += 1\n",
    "    \n",
    "print()\n",
    "print(\"inverse\", sorted(invers_similar_ings))\n",
    "\n",
    "print(\"counts\")\n",
    "for i in sorted(list(invers_similar_ings.items()), key=lambda v: v[1])[-10:]:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "print(\"most similar\", model.wv.most_similar(list(invers_similar_ings)))\n",
    "\n",
    "print(\"negative\")\n",
    "model.wv.most_similar(negative=w2v_ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
